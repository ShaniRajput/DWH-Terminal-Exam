# -*- coding: utf-8 -*-
"""Data Warehouse & Mining (Lab Assignment).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XAVI2UnHmNpFnoNodyAqGE9KtcDdN_W8

**Importing Libraries**
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn import tree
from sklearn.naive_bayes import BernoulliNB
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from scipy.cluster.hierarchy import dendrogram, linkage

"""**Importing Data**"""

data = pd.read_csv('healthcare-dataset-stroke-data.csv')
print(data.head())

"""**Cleaning Data**"""

print(data.isnull().mean())

print(data.dtypes)

data = data.dropna()
data.drop('id', inplace=True, axis=1)
print(data.head())

data['gender'] = data['gender'].astype('category')
data['ever_married'] = data['ever_married'].astype('category')
data['work_type'] = data['work_type'].astype('category')
data['Residence_type'] = data['Residence_type'].astype('category')
data['smoking_status'] = data['smoking_status'].astype('category')

data['gender_code'] = data.gender.cat.codes
data['ever_married_code'] = data.ever_married.cat.codes
data['work_type_code'] = data.work_type.cat.codes
data['Residence_type_code'] = data.Residence_type.cat.codes
data['smoking_status_code'] = data.smoking_status.cat.codes

"""**Implementation of Decision Tree**"""

features = ['gender_code', 'age', 'hypertension', 'heart_disease', 'ever_married_code', 'work_type_code', 'Residence_type_code', 'avg_glucose_level', 'bmi', 'smoking_status_code']

X = data[features]
Y = data['stroke']


x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)

dt_clf = DecisionTreeClassifier(criterion="entropy", max_depth=5)
dt_clf = dt_clf.fit(x_train,y_train)
y_pred = dt_clf.predict(x_test)

print("Accuracy:", round(metrics.accuracy_score(y_test, y_pred) * 100, 2))
print('\nClassificaion Report:\n')
print(metrics.classification_report(y_pred, y_test))

tree.plot_tree(dt_clf, feature_names=features)

"""**Implementation of Naive Bayes**"""

nb = BernoulliNB()
y_pred = nb.fit(x_train, y_train).predict(x_test)

print("Accuracy:", round(metrics.accuracy_score(y_test, y_pred) * 100, 2))
print('\nClassificaion Report:\n')
print(metrics.classification_report(y_pred, y_test))

"""**Importing Data**"""

data = pd.read_csv('petrol_consumption.csv')
data.head()

"""**Implementation of Linear Regression**"""

features = ['Petrol_tax', 'Average_income', 'Paved_Highways','Population_Driver_licence(%)']

for feature in features:
    plt.figure()
    sns.regplot(x=feature, y='Petrol_Consumption', data=data).set(title=f'Regression plot of {feature} and Petrol Consumption');

"""**Importing Data**"""

data = pd.read_csv('loan_prediction.csv')
data.head()

"""**Implementation of K-Mean Clustering**"""

X = data[["ApplicantIncome", "LoanAmount"]].values
kmean = KMeans(n_clusters=3)
kmean.fit(X)
labels = kmean.predict(X)
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')

"""**Implementation of Hierarchical Clustering**"""

Z = linkage(X[0:20], 'ward')
plt.figure()
dendrogram(Z, labels=X[0:20], orientation='right', distance_sort='descending', show_leaf_counts=False, p=5)
plt.show()